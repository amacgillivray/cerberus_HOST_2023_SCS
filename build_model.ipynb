{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport pathlib\nimport PIL\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Input, Conv2D, MaxPool2D, add\nfrom keras.layers import Dense, BatchNormalization, GlobalAveragePooling2D\nfrom keras import Model\n\n#######################\n# Runtime Configuration\n#######################\n\n# When true, may do extra calculations and print more information\nDEBUG = False\n\n# Whether or not to omit files specified in \"exclude\" from the \n# training data. Some files are marked as exclude due to having\n# characteristics that contradict a normal example of their \n# labeled class (counterfeit or authentic)\nUSE_EXCLUDE = True\n\n# When true, will export processed images to the file system\nEXPORT_PROCESSED = False\n\n# The folder to write processed images to, if EXPORT_PROCESSED is True\nEXPORT_DIR = \"/kaggle/working/\"\n\n# Inputs will be cropped to omit any rows / columns whos grayscale value is always higher than this\nFILTER_BRIGHTNESS = 250\n\n# Size of images that will be used to train the CNN\nIMAGE_SIZE = (325, 325)\n\n# Keras Model Configuration\nMETRICS = ['Accuracy'] \nLOSS = 'binary_crossentropy'\nOPTIMIZER = 'Adam'\nBATCH_SIZE = 10\nEPOCHS = 20\n\n# Output Filter - Confidence Threshold\n# Require > (1-CONF_T) confidence of genuine in order to apply genuine label\nCONF_T = 0.15\n\n\n####################\n# Paths, Class Names\n####################\nclass_names = ['genuine', 'counterfeit']\nclass_names_label = {class_name: i for i, class_name in enumerate(class_names)}\n\ntraining_path = \"../input/host-23/phase1-workspace\"\ndata_dir = pathlib.Path(training_path)\ncounterfeit = list(data_dir.glob('counterfeit/*'))\ngenuine = list(data_dir.glob('genuine/*'))\n\ntest_path = \"../input/host-23/\"\ntest_dir = pathlib.Path(test_path)\nt_counterfeit = list(test_dir.glob('counterfeit_test/*'))\nt_genuine = list(test_dir.glob('genuine_test/*'))\n\nholdout_path = \"../input/host-23/Holdout_data\"\n\n#######################\n# Global Functions\n#######################\n\n# Get the rows and columns of an image that contain something other than just whitespace\n# Whitespace threshold is set by FILTER_BRIGHTNESS\ndef find_img_bounds( img_path ):\n    gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  ;\n    rows = ~np.all(gray >= FILTER_BRIGHTNESS, axis = 1);\n    cols = ~np.all(gray >= FILTER_BRIGHTNESS, axis = 0);\n    return (rows, cols);\n\n# Trims an image with the given rows and bounds\ndef trim_img(image, rows, cols, is3d = False):\n    trimmed_image = []\n    if (~is3d):\n        t1 = image[rows, :]\n        trimmed_image = t1[:, cols]\n    else:\n        t1 = image[rows, :, :]\n        trimmed_image = t1[:, cols, :]\n    return trimmed_image\n\ndef process_img(img_path):    \n    (rows, cols) = find_img_bounds(img_path)\n    \n    # Kernel Sizes for Sobel, Gaussian Blur\n    b_sz = 3;\n    s_sz = 5;\n    \n    # Work with gray image\n    gray = cv2.imread(img_path)\n    gray = cv2.cvtColor(gray, cv2.COLOR_BGR2GRAY)\n    \n    # Trim, then resize, then blur the grayscale image\n    image = trim_img(gray, rows, cols)\n    image = cv2.resize(image, IMAGE_SIZE)\n    smoothed = image #cv2.GaussianBlur(image,(b_sz,b_sz), 5) #higher acc with sigmax = 5?\n    \n    # Extract features with laplacian, sobel (x), sobel (y)\n    laplace = cv2.Laplacian(smoothed, cv2.CV_64F)\n    sobelx  = cv2.Sobel(smoothed, cv2.CV_64F, 1, 0, ksize=s_sz)\n    sobely  = cv2.Sobel(smoothed, cv2.CV_64F, 0, 1, ksize=s_sz)\n    \n    # Create a combined image with: \n    #  blue:  laplacian\n    #  red:   sobelx\n    #  green: sobely\n    return cv2.merge([laplace, sobelx, sobely])\n\n# Predict labels of a data set, then apply a confidence threshold. \n# -----\n# Args:\n#  m:    model       (Keras Model)\n#  ds:   data set    (Input)\ndef predict_with_confidence( m, ds ): \n    predictions = model.predict(x=ds)\n    filtered_preds = []\n    if DEBUG:\n        print(predictions)\n    for idx, pred in enumerate(predictions) :\n        if (pred <= CONF_T):\n            filtered_preds.append(0)\n        else:\n            filtered_preds.append(1)\n    return filtered_preds\n\n# Predict labels of a data set, then apply a confidence threshold. \n# Compare predictions with the known labels of the inputs.\n# -----\n# Args:\n#  m:    model       (Keras Model)\n#  ds:   data set    (Input)\n#  dl:   data labels \ndef predict_with_confidence_knownvals( m, ds, dl ):\n    filtered_preds = predict_with_confidence(m, ds)\n    label_length = len(dl)\n    correct_preds = 0\n    auth_preds = 0\n    cfit_preds = 0\n    for i in range(0, label_length) :\n        if (filtered_preds[i] == dl[i]):\n            correct_preds += 1\n        if (filtered_preds[i] == 0):\n            auth_preds += 1\n        else:\n            cfit_preds += 1\n    print (\"Correct Predictions: \", correct_preds)\n    print (\"Total Predictions: \", label_length)\n    print (\"Accuracy: \", correct_preds/label_length)\n    \n    print (\"Confusion: \")\n    cm = tf.math.confusion_matrix(labels=dl, predictions=filtered_preds)\n    print (cm)\n    print (\"Authentics Predicted: \", auth_preds)\n    print (\"Counterfeits Predicted: \", cfit_preds)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:50:02.509726Z","iopub.execute_input":"2023-03-15T22:50:02.510189Z","iopub.status.idle":"2023-03-15T22:50:13.239505Z","shell.execute_reply.started":"2023-03-15T22:50:02.510149Z","shell.execute_reply":"2023-03-15T22:50:13.238440Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Files to exclude -- \n#  These are images of either counterfeit IC components that look too authentic,\n#  or authentic ICs that look like counterfeits. \nexclude = [\n     \"A-D-64QFP-43B-D\"  # large scratch on surface\n    ,\"A-O-08DIP-31B-D\"  # irregular left edge\n    ,\"A-O-08DIP-33B-D\"  # irregular left edge\n    ,\"A-O-08DIP-33F-D\"  # irregular right edge\n    ,\"A-O-08DIP-40B-D\"  # irregular right edge\n    ,\"A-O-08DIP-40F-D\"  # heavily worn\n    ,\"A-D-64QFP-01B-SM\" # gunk on pins\n    ,\"A-D-64QFP-01F-SM\" # front side of the previous item\n    ,\"A-D-64QFP-05B-SM\" # bent pin\n    ,\"A-O-08DIP-21B-SM\" # irregular left edge\n    ,\"A-O-08DIP-24F-SM\" # irreg sfc, silkscreen\n    ,\"A-O-08DIP-25F-SM\" # heavily worn\n    ,\"C-T-64QFP-14B-SM\" # cleaner than many authentic items\n    ,\"C-O-08DIP-16B-SM\" # too clean\n]\n\n#################\n# load_data() fn\n#################\n# Loads the data from the counterfeit and genuine folders, and applies some processing.\ndef load_data( DIRECTORY, CATEGORY, DIRS = [] ):\n    if (len(DIRS) == 0):\n        print (\"Setting DIRS to CATEGORY...\")\n        DIRS = CATEGORY\n    assert (len(DIRS) == len(CATEGORY)), \"Length of CATEGORY and DIRS arguments must be equal, if DIRS is specified\"\n    output = []\n    for category in CATEGORY:\n        \n        pwd = DIRS[CATEGORY.index(category)]\n        path = os.path.join(DIRECTORY, pwd)\n        folder = path\n        images = []\n        labels = []\n        label = class_names_label[category]\n        \n        print(\"Loading {}\".format(category))\n        print (\"Applying label: \", label)\n            \n        for file in os.listdir(folder):\n            \n            # Optionally skip some images that were selected to be \n            # excluded from the model's training data\n            if USE_EXCLUDE:\n#                 if \"QFP\" in file:\n#                     print (\"Skipping \" + file + \" (skipping squares)\")\n#                     continue\n                if file.rstrip(\".png\") in exclude:\n                    print (\"Skipping \" + file + \" (specified exclude)\")\n                    continue\n            img_path = os.path.join(folder, file)\n            testpath = cv2.imread(img_path)\n        \n            if testpath is None:\n                print(\"Error: Unable to read file '\", img_path, \"'. Skipping.'\")\n                continue\n            \n            # Process the Image, optionally export so the processed variant can\n            # be inspected for correctness.\n            img = process_img(img_path)\n            if EXPORT_PROCESSED:\n                procPath = EXPORT_DIR + file.rstrip(\".png\") + \"_TEST\" + \".png\"\n                print(\"Writing processed image to: \" + procPath)\n                cv2.imwrite(procPath, img)\n            \n            # Append the processed image to the output, with the associated label.\n            images.append(img)\n            labels.append(label)\n            \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')\n        output.append((images, labels))\n    return output","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:50:13.244326Z","iopub.execute_input":"2023-03-15T22:50:13.245593Z","iopub.status.idle":"2023-03-15T22:50:13.260405Z","shell.execute_reply.started":"2023-03-15T22:50:13.245538Z","shell.execute_reply":"2023-03-15T22:50:13.259253Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Training Data\nHere, we'll build the training data by reading from the `genuine` and `counterfeit` directories in `phase1-workspace`.","metadata":{}},{"cell_type":"code","source":"# Load data from the counterfeit, genuine folders\n(counterfeit_images, counterfeit_labels), (genuine_images, genuine_labels) = load_data(training_path,[\"counterfeit\", \"genuine\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:50:13.261628Z","iopub.execute_input":"2023-03-15T22:50:13.261964Z","iopub.status.idle":"2023-03-15T22:50:44.786687Z","shell.execute_reply.started":"2023-03-15T22:50:13.261934Z","shell.execute_reply":"2023-03-15T22:50:44.785393Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Setting DIRS to CATEGORY...\nLoading counterfeit\nApplying label:  1\nSkipping C-O-08DIP-16B-SM.png (specified exclude)\nSkipping C-T-64QFP-14B-SM.png (specified exclude)\nLoading genuine\nApplying label:  0\nError: Unable to read file ' ../input/host-23/phase1-workspace/genuine/A-D-64QFP-29F-SM.psd '. Skipping.'\nSkipping A-O-08DIP-21B-SM.png (specified exclude)\nSkipping A-O-08DIP-25F-SM.png (specified exclude)\nSkipping A-O-08DIP-33F-D.png (specified exclude)\nSkipping A-O-08DIP-40F-D.png (specified exclude)\nSkipping A-D-64QFP-43B-D.png (specified exclude)\nSkipping A-D-64QFP-01B-SM.png (specified exclude)\nSkipping A-O-08DIP-24F-SM.png (specified exclude)\nSkipping A-O-08DIP-33B-D.png (specified exclude)\nSkipping A-D-64QFP-05B-SM.png (specified exclude)\nSkipping A-D-64QFP-01F-SM.png (specified exclude)\nSkipping A-O-08DIP-31B-D.png (specified exclude)\nSkipping A-O-08DIP-40B-D.png (specified exclude)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create training data from the processed images, \n# mixing counterfeit, authentic, dslr, and microscope data\ntrain_images = np.append(counterfeit_images, genuine_images, axis=0)\ntrain_labels = np.append(counterfeit_labels, genuine_labels, axis=0)\n\nif DEBUG:\n    print(train_images.shape)\n    print(train_labels.shape)\n    print(train_images)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:50:44.789881Z","iopub.execute_input":"2023-03-15T22:50:44.790548Z","iopub.status.idle":"2023-03-15T22:50:44.841257Z","shell.execute_reply.started":"2023-03-15T22:50:44.790509Z","shell.execute_reply":"2023-03-15T22:50:44.839879Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Test Data\nNext, we'll build the test set by reading from the `genuine_test` and `counterfeit_test` directories in the top level of `host-23`.","metadata":{}},{"cell_type":"code","source":"# Load data from the counterfeit_test, genuine_test folders\n(t_counterfeit_images, t_counterfeit_labels), (t_genuine_images, t_genuine_labels) = load_data(\n    test_path, # DIRECTORY\n    [\"counterfeit\", \"genuine\"], # CATEGORY\n    [\"counterfeit_test\", \"genuine_test\"] # DIRS\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:50:44.843749Z","iopub.execute_input":"2023-03-15T22:50:44.844103Z","iopub.status.idle":"2023-03-15T22:50:52.571183Z","shell.execute_reply.started":"2023-03-15T22:50:44.844069Z","shell.execute_reply":"2023-03-15T22:50:52.569854Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Loading counterfeit\nApplying label:  1\nLoading genuine\nApplying label:  0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create test data\ntest_images = np.append(t_counterfeit_images, t_genuine_images, axis=0)\ntest_labels = np.append(t_counterfeit_labels, t_genuine_labels, axis=0)\n\nif DEBUG:\n    print(test_images.shape)\n    print(test_labels.shape)\n    print(test_images)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:50:52.572600Z","iopub.execute_input":"2023-03-15T22:50:52.572998Z","iopub.status.idle":"2023-03-15T22:50:52.584420Z","shell.execute_reply.started":"2023-03-15T22:50:52.572953Z","shell.execute_reply":"2023-03-15T22:50:52.583062Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Build Model\nThe following cells build the model, using the Keras Model class.","metadata":{}},{"cell_type":"code","source":"inputs = Input(shape=(IMAGE_SIZE + (3,)))\n\nn = 8\nb1a = \"elu\"\nb2a = b1a\nb3a = b1a\n\n\nx = Conv2D(n, (3, 3), activation = b1a)(inputs)\nx = BatchNormalization()(x)\nx = Conv2D(n*2, (3, 3), activation = b1a)(x)\nblock_1_output = MaxPool2D(pool_size=(3, 3))(x)\n\nx = Conv2D(n*2, (3, 3), activation = b2a, padding = 'same')(block_1_output)\nx = BatchNormalization()(x)\nx = Conv2D(n*2, (3, 3), activation = b2a, padding = 'same')(x)\nblock_2_output = add([x, block_1_output])\n\nx = Conv2D(n*2, (3, 3), activation = b3a, padding = 'same')(block_2_output)\nx = BatchNormalization()(x)\nx = Conv2D(n*2, (3, 3), activation = b3a, padding = 'same')(x)\nblock_3_output = add([x, block_2_output])\n\nx = Conv2D(n*2*2, (3, 3), activation = 'elu')(block_3_output)\nx = MaxPool2D(pool_size = (2, 2))(x)\nx = GlobalAveragePooling2D()(x)\nx = Dense(n*2*2*2, activation = 'elu')(x)\n\noutput = Dense(1, activation = 'sigmoid')(x)\n\nif DEBUG:\n    print(inputs.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:50:52.586051Z","iopub.execute_input":"2023-03-15T22:50:52.586499Z","iopub.status.idle":"2023-03-15T22:50:53.144275Z","shell.execute_reply.started":"2023-03-15T22:50:52.586462Z","shell.execute_reply":"2023-03-15T22:50:53.143114Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs, output)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:50:53.146235Z","iopub.execute_input":"2023-03-15T22:50:53.146774Z","iopub.status.idle":"2023-03-15T22:50:53.162132Z","shell.execute_reply.started":"2023-03-15T22:50:53.146717Z","shell.execute_reply":"2023-03-15T22:50:53.160772Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.compile(metrics=METRICS, loss=LOSS, optimizer=OPTIMIZER)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:50:53.163507Z","iopub.execute_input":"2023-03-15T22:50:53.164195Z","iopub.status.idle":"2023-03-15T22:50:53.255157Z","shell.execute_reply.started":"2023-03-15T22:50:53.164143Z","shell.execute_reply":"2023-03-15T22:50:53.253987Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 325, 325, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 323, 323, 8)  224         ['input_1[0][0]']                \n                                                                                                  \n batch_normalization (BatchNorm  (None, 323, 323, 8)  32         ['conv2d[0][0]']                 \n alization)                                                                                       \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 321, 321, 16  1168        ['batch_normalization[0][0]']    \n                                )                                                                 \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 107, 107, 16  0           ['conv2d_1[0][0]']               \n                                )                                                                 \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 107, 107, 16  2320        ['max_pooling2d[0][0]']          \n                                )                                                                 \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 107, 107, 16  64         ['conv2d_2[0][0]']               \n rmalization)                   )                                                                 \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 107, 107, 16  2320        ['batch_normalization_1[0][0]']  \n                                )                                                                 \n                                                                                                  \n add (Add)                      (None, 107, 107, 16  0           ['conv2d_3[0][0]',               \n                                )                                 'max_pooling2d[0][0]']          \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 107, 107, 16  2320        ['add[0][0]']                    \n                                )                                                                 \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 107, 107, 16  64         ['conv2d_4[0][0]']               \n rmalization)                   )                                                                 \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 107, 107, 16  2320        ['batch_normalization_2[0][0]']  \n                                )                                                                 \n                                                                                                  \n add_1 (Add)                    (None, 107, 107, 16  0           ['conv2d_5[0][0]',               \n                                )                                 'add[0][0]']                    \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 105, 105, 32  4640        ['add_1[0][0]']                  \n                                )                                                                 \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 52, 52, 32)  0           ['conv2d_6[0][0]']               \n                                                                                                  \n global_average_pooling2d (Glob  (None, 32)          0           ['max_pooling2d_1[0][0]']        \n alAveragePooling2D)                                                                              \n                                                                                                  \n dense (Dense)                  (None, 64)           2112        ['global_average_pooling2d[0][0]'\n                                                                 ]                                \n                                                                                                  \n dense_1 (Dense)                (None, 1)            65          ['dense[0][0]']                  \n                                                                                                  \n==================================================================================================\nTotal params: 17,649\nTrainable params: 17,569\nNon-trainable params: 80\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(\n    train_images, \n    train_labels, \n    batch_size=BATCH_SIZE, \n    epochs=EPOCHS,\n    validation_data=(test_images,test_labels),\n    shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:50:53.259019Z","iopub.execute_input":"2023-03-15T22:50:53.259393Z","iopub.status.idle":"2023-03-15T22:54:05.302896Z","shell.execute_reply.started":"2023-03-15T22:50:53.259358Z","shell.execute_reply":"2023-03-15T22:54:05.301054Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/20\n9/9 [==============================] - 13s 1s/step - loss: 0.7720 - Accuracy: 0.4767 - val_loss: 1.6083 - val_Accuracy: 0.5000\nEpoch 2/20\n9/9 [==============================] - 10s 1s/step - loss: 0.6697 - Accuracy: 0.5814 - val_loss: 0.9450 - val_Accuracy: 0.5000\nEpoch 3/20\n9/9 [==============================] - 10s 1s/step - loss: 0.6270 - Accuracy: 0.6512 - val_loss: 0.9913 - val_Accuracy: 0.5000\nEpoch 4/20\n9/9 [==============================] - 10s 1s/step - loss: 0.5999 - Accuracy: 0.6977 - val_loss: 0.7667 - val_Accuracy: 0.5000\nEpoch 5/20\n9/9 [==============================] - 9s 1s/step - loss: 0.5751 - Accuracy: 0.6744 - val_loss: 0.9935 - val_Accuracy: 0.5000\nEpoch 6/20\n9/9 [==============================] - 9s 1s/step - loss: 0.5685 - Accuracy: 0.7558 - val_loss: 0.8247 - val_Accuracy: 0.5500\nEpoch 7/20\n9/9 [==============================] - 9s 1s/step - loss: 0.5028 - Accuracy: 0.8140 - val_loss: 1.2283 - val_Accuracy: 0.5000\nEpoch 8/20\n9/9 [==============================] - 10s 1s/step - loss: 0.6156 - Accuracy: 0.6744 - val_loss: 0.8438 - val_Accuracy: 0.5500\nEpoch 9/20\n9/9 [==============================] - 9s 1s/step - loss: 0.5112 - Accuracy: 0.7791 - val_loss: 0.7917 - val_Accuracy: 0.6500\nEpoch 10/20\n9/9 [==============================] - 9s 1s/step - loss: 0.4508 - Accuracy: 0.8140 - val_loss: 1.3243 - val_Accuracy: 0.5000\nEpoch 11/20\n9/9 [==============================] - 9s 1s/step - loss: 0.4883 - Accuracy: 0.8140 - val_loss: 0.9445 - val_Accuracy: 0.6000\nEpoch 12/20\n9/9 [==============================] - 9s 1s/step - loss: 0.3963 - Accuracy: 0.8605 - val_loss: 1.4610 - val_Accuracy: 0.5000\nEpoch 13/20\n9/9 [==============================] - 9s 1s/step - loss: 0.4103 - Accuracy: 0.8488 - val_loss: 0.9004 - val_Accuracy: 0.6500\nEpoch 14/20\n9/9 [==============================] - 9s 1s/step - loss: 0.4222 - Accuracy: 0.8488 - val_loss: 2.0670 - val_Accuracy: 0.5000\nEpoch 15/20\n9/9 [==============================] - 10s 1s/step - loss: 0.4098 - Accuracy: 0.8605 - val_loss: 0.8460 - val_Accuracy: 0.6500\nEpoch 16/20\n9/9 [==============================] - 9s 1s/step - loss: 0.3694 - Accuracy: 0.8837 - val_loss: 1.3489 - val_Accuracy: 0.5000\nEpoch 17/20\n9/9 [==============================] - 9s 1s/step - loss: 0.2987 - Accuracy: 0.8837 - val_loss: 1.3559 - val_Accuracy: 0.5000\nEpoch 18/20\n9/9 [==============================] - 10s 1s/step - loss: 0.4789 - Accuracy: 0.8023 - val_loss: 2.2154 - val_Accuracy: 0.5000\nEpoch 19/20\n9/9 [==============================] - 9s 1s/step - loss: 0.3177 - Accuracy: 0.8721 - val_loss: 1.4785 - val_Accuracy: 0.5000\nEpoch 20/20\n9/9 [==============================] - 9s 1s/step - loss: 0.2808 - Accuracy: 0.9070 - val_loss: 1.5918 - val_Accuracy: 0.5000\n","output_type":"stream"}]},{"cell_type":"code","source":"def hist_pretty( h, field ):\n    i = 1\n    print(\"\\n\", field, \":\");\n    values = h.history[field]\n    for v in values:\n        print (\"\\tE\", i, \":\\t\", v)\n        i += 1\n\nfor f in ['loss', 'Accuracy', 'val_loss', 'val_Accuracy']:\n    hist_pretty(history, f)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:54:05.305158Z","iopub.execute_input":"2023-03-15T22:54:05.305824Z","iopub.status.idle":"2023-03-15T22:54:05.314990Z","shell.execute_reply.started":"2023-03-15T22:54:05.305779Z","shell.execute_reply":"2023-03-15T22:54:05.313870Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\n loss :\n\tE 1 :\t 0.7719523310661316\n\tE 2 :\t 0.6696892380714417\n\tE 3 :\t 0.6269795894622803\n\tE 4 :\t 0.5999024510383606\n\tE 5 :\t 0.5750945210456848\n\tE 6 :\t 0.5684803128242493\n\tE 7 :\t 0.5028275847434998\n\tE 8 :\t 0.6155943870544434\n\tE 9 :\t 0.5112050175666809\n\tE 10 :\t 0.4508495330810547\n\tE 11 :\t 0.48825064301490784\n\tE 12 :\t 0.39627736806869507\n\tE 13 :\t 0.41030359268188477\n\tE 14 :\t 0.42224037647247314\n\tE 15 :\t 0.40978267788887024\n\tE 16 :\t 0.36944475769996643\n\tE 17 :\t 0.29871684312820435\n\tE 18 :\t 0.4788856506347656\n\tE 19 :\t 0.3177022933959961\n\tE 20 :\t 0.2808331847190857\n\n Accuracy :\n\tE 1 :\t 0.4767441749572754\n\tE 2 :\t 0.5813953280448914\n\tE 3 :\t 0.6511628031730652\n\tE 4 :\t 0.6976743936538696\n\tE 5 :\t 0.6744186282157898\n\tE 6 :\t 0.7558139562606812\n\tE 7 :\t 0.8139534592628479\n\tE 8 :\t 0.6744186282157898\n\tE 9 :\t 0.7790697813034058\n\tE 10 :\t 0.8139534592628479\n\tE 11 :\t 0.8139534592628479\n\tE 12 :\t 0.8604651093482971\n\tE 13 :\t 0.8488371968269348\n\tE 14 :\t 0.8488371968269348\n\tE 15 :\t 0.8604651093482971\n\tE 16 :\t 0.8837209343910217\n\tE 17 :\t 0.8837209343910217\n\tE 18 :\t 0.8023256063461304\n\tE 19 :\t 0.8720930218696594\n\tE 20 :\t 0.9069767594337463\n\n val_loss :\n\tE 1 :\t 1.6082805395126343\n\tE 2 :\t 0.9450470209121704\n\tE 3 :\t 0.9913023114204407\n\tE 4 :\t 0.7666885852813721\n\tE 5 :\t 0.993451714515686\n\tE 6 :\t 0.8247431516647339\n\tE 7 :\t 1.2283278703689575\n\tE 8 :\t 0.8438167572021484\n\tE 9 :\t 0.7916529178619385\n\tE 10 :\t 1.3243180513381958\n\tE 11 :\t 0.9445487856864929\n\tE 12 :\t 1.4610453844070435\n\tE 13 :\t 0.9004179835319519\n\tE 14 :\t 2.066983222961426\n\tE 15 :\t 0.8460482358932495\n\tE 16 :\t 1.3489145040512085\n\tE 17 :\t 1.3558813333511353\n\tE 18 :\t 2.2154479026794434\n\tE 19 :\t 1.4784553050994873\n\tE 20 :\t 1.5918444395065308\n\n val_Accuracy :\n\tE 1 :\t 0.5\n\tE 2 :\t 0.5\n\tE 3 :\t 0.5\n\tE 4 :\t 0.5\n\tE 5 :\t 0.5\n\tE 6 :\t 0.550000011920929\n\tE 7 :\t 0.5\n\tE 8 :\t 0.550000011920929\n\tE 9 :\t 0.6499999761581421\n\tE 10 :\t 0.5\n\tE 11 :\t 0.6000000238418579\n\tE 12 :\t 0.5\n\tE 13 :\t 0.6499999761581421\n\tE 14 :\t 0.5\n\tE 15 :\t 0.6499999761581421\n\tE 16 :\t 0.5\n\tE 17 :\t 0.5\n\tE 18 :\t 0.5\n\tE 19 :\t 0.5\n\tE 20 :\t 0.5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Test Confidence Filter on Training Data\nHere, we'll apply our extra post-processing of the predictions and see how accurate our model is when predicting labels of the training set\n","metadata":{}},{"cell_type":"code","source":"# Ensure that all images - including those we excluded from the training set when building the model - are tested\nUSE_EXCLUDE = False\n(ci_all, cl_all), (gi_all, gl_all) = load_data(training_path,[\"counterfeit\", \"genuine\"])\ncf_iset = np.append(ci_all, gi_all, axis=0) # Confidence Filter - Image Set\ncf_lset = np.append(cl_all, gl_all, axis=0) # Confidence Filter - Label Set","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:54:05.316763Z","iopub.execute_input":"2023-03-15T22:54:05.317176Z","iopub.status.idle":"2023-03-15T22:54:38.380662Z","shell.execute_reply.started":"2023-03-15T22:54:05.317130Z","shell.execute_reply":"2023-03-15T22:54:38.379685Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Setting DIRS to CATEGORY...\nLoading counterfeit\nApplying label:  1\nLoading genuine\nApplying label:  0\nError: Unable to read file ' ../input/host-23/phase1-workspace/genuine/A-D-64QFP-29F-SM.psd '. Skipping.'\n","output_type":"stream"}]},{"cell_type":"code","source":"predict_with_confidence_knownvals( model, cf_iset, cf_lset )","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:54:38.381916Z","iopub.execute_input":"2023-03-15T22:54:38.382631Z","iopub.status.idle":"2023-03-15T22:54:41.356148Z","shell.execute_reply.started":"2023-03-15T22:54:38.382595Z","shell.execute_reply":"2023-03-15T22:54:41.354977Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"4/4 [==============================] - 3s 584ms/step\nCorrect Predictions:  75\nTotal Predictions:  100\nAccuracy:  0.75\nConfusion: \ntf.Tensor(\n[[60  0]\n [25 15]], shape=(2, 2), dtype=int32)\nAuthentics Predicted:  85\nCounterfeits Predicted:  15\n","output_type":"stream"}]},{"cell_type":"code","source":"predict_with_confidence_knownvals( model, test_images, test_labels )","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:54:41.359395Z","iopub.execute_input":"2023-03-15T22:54:41.359980Z","iopub.status.idle":"2023-03-15T22:54:41.932971Z","shell.execute_reply.started":"2023-03-15T22:54:41.359942Z","shell.execute_reply":"2023-03-15T22:54:41.932126Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 1s 521ms/step\nCorrect Predictions:  13\nTotal Predictions:  20\nAccuracy:  0.65\nConfusion: \ntf.Tensor(\n[[10  0]\n [ 7  3]], shape=(2, 2), dtype=int32)\nAuthentics Predicted:  17\nCounterfeits Predicted:  3\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"Image_Classification\")\nsave_model = input(\"Do you wish to save this model [y/n]: \").strip().lower()\n\nif save_model == 'y' or save_model == 'yes':\n    model_name = input(\"Model Name: \").strip()\n    try:\n        tf.keras.models.save_model(model, EXPORT_DIR + model_name + \".hdf5\")\n    except:\n        print(\"Saving failed...\")","metadata":{"execution":{"iopub.status.busy":"2023-03-15T22:54:41.934021Z","iopub.execute_input":"2023-03-15T22:54:41.934337Z","iopub.status.idle":"2023-03-15T22:56:36.329908Z","shell.execute_reply.started":"2023-03-15T22:54:41.934308Z","shell.execute_reply":"2023-03-15T22:56:36.328998Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdin","text":"Do you wish to save this model [y/n]:  y\nModel Name:  inferior\n"}]}]}